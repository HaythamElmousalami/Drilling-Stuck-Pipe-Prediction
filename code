# -*- coding: utf-8 -*-
"""
Created on Sat Apr 13 19:57:13 2019

@author: Haytham
"""

# NOtes
# Needs ........  AUC , Assessments for 


# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Importing the dataset
dataset = pd.read_csv('Data augmanted 5.csv')
X = dataset.iloc[0:103 , 0:7].values
y = dataset.iloc[0:103 , -1].values

############  Correation matrix ####################
# Step 0 - Read the dataset, calculate column correlations and make a seaborn heatmap

import seaborn as sns

corr = dataset.corr()
ax = sns.heatmap(
    corr, 
    vmin=-1, vmax=1, center=0,
    cmap=sns.diverging_palette(20, 220, n=200),
    square=True
)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right'
);

print(ax)

#########  

#pd.scatter_matrix(dataset, figsize=(12, 12))
#plt.show()

################  a Boxplot

dataset.plot(kind='box', figsize=(16, 8))
plt.show()

############## Quick and Dirty Data Analysis with Pandas // Mastery

print(dataset)

print(dataset.describe())
print(dataset.boxplot(figsize=(16, 8)))
print(dataset.hist(figsize=(16, 8)))

#from pandas.plotting import scatter_matrix
#scatter_matrix(dataset, alpha=0.2, figsize=(10, 10), diagonal='kde')


# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

########### feature engineering #################
 

########### correlation matrix #################


########### Regression methods #################





########### logistic regression #################
  
# Fitting Logistic Regression to the Training set
from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 0)
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred_Logistic = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_logistic = confusion_matrix(y_test, y_pred_Logistic)

######### AUC ##############
import numpy as np
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_Logistic, pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_logistic = metrics.auc(fpr, tpr)

######### AP ##############
import numpy as np
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_Logistic))   
average_precision_score_Logistic = average_precision_score(y_test, y_pred_Logistic)

######### AUC another way ##############

import numpy as np
from sklearn.metrics import roc_auc_score

print ("AUC_logistic = ",roc_auc_score(y_test, y_pred_Logistic))

#### Applying k-Fold Cross Validation ### look at course ##

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)
K_cross_log = accuracies.mean()
K_cross_log_Std = accuracies.std()


###############  Draw AUC (ML mastery) #############################

# roc curve and auc
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot

# keep probabilities for the positive outcome only
#y_pred_Logistic = y_pred_Logistic[:, 1]

# calculate AUC
auc = roc_auc_score(y_test, y_pred_Logistic)
print('AUC: %.3f' % auc)
# calculate roc curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_Logistic)
# plot no skill
pyplot.plot([0, 1], [0, 1], linestyle='--')
# plot the roc curve for the model
pyplot.plot(fpr, tpr, marker='.')
# show the plot
pyplot.show()

############## accuracy_score ####################################

from sklearn.metrics import accuracy_score

accuracy_score_logistic = accuracy_score(y_test, y_pred_Logistic, normalize=False)
print("accuracy_score_logistic =",accuracy_score_logistic)

########### KNN #################

# Fitting K-NN to the Training set
from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred_KNN = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_KNN = confusion_matrix(y_test, y_pred_KNN)

######### AUC ##############
import numpy as np
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_KNN, pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_KNN = metrics.auc(fpr, tpr)

######### AP ##############
import numpy as np
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_KNN))   
average_precision_score_KNN = average_precision_score(y_test, y_pred_KNN)

########### SVM #################

# Fitting SVM to the Training set
from sklearn.svm import SVC
classifier = SVC(kernel = 'rbf', random_state = 0)
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred_SVC = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_SVC = confusion_matrix(y_test, y_pred_SVC)

######### AUC ##############
import numpy as np
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_SVC, pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_SVM = metrics.auc(fpr, tpr)

######### AP ##############
import numpy as np
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_SVC))   
average_precision_score_SVM = average_precision_score(y_test, y_pred_SVC)

########### Naive Bayes #################

# Fitting Naive Bayes to the Training set
from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred_naive = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_naive = confusion_matrix(y_test, y_pred_naive)

######### AUC ##############
import numpy as np
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_naive, pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_naive = metrics.auc(fpr, tpr)

######### AP ##############
import numpy as np
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_naive))   
average_precision_score_naive = average_precision_score(y_test, y_pred_naive)

########### DT #################

# Fitting Decision Tree Classification to the Training set
from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred_DT = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_DT = confusion_matrix(y_test, y_pred_DT)

######### AUC ##############
import numpy as np
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_DT, pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_DT = metrics.auc(fpr, tpr)

######### AP ##############
import numpy as np
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_DT))   
average_precision_score_DT = average_precision_score(y_test, y_pred_DT)

########### Random Forest Classification #################

# Fitting Random Forest Classification to the Training set
from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred_RF = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_RF = confusion_matrix(y_test, y_pred_RF)

######### AUC ##############
import numpy as np
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_RF , pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_RF = metrics.auc(fpr, tpr)

######### AP ##############
import numpy as np
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_RF ))   
average_precision_score_RF = average_precision_score(y_test, y_pred_RF )


# XGBoost #############################################
# Install xgboost following the instructions on this link: http://xgboost.readthedocs.io/en/latest/build.html#

# Fitting XGBoost to the Training set
from xgboost import XGBClassifier
Reg = XGBClassifier()
Reg.fit(X_train, y_train)


# Predicting the Test set results
y_pred_XGB = Reg.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_XGB = confusion_matrix(y_test, y_pred_XGB)

# feature importance
from xgboost import plot_importance
from matplotlib import pyplot
plot_importance(Reg)
pyplot.show()

######### AUC ##############
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_XGB , pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_XGB = metrics.auc(fpr, tpr)

######### AP ##############
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_XGB ))   
average_precision_score_XGB = average_precision_score(y_test, y_pred_XGB )


#   ANNs   ################    DNNs      ######################################################
##############################################################

from sklearn.neural_network import MLPClassifier
clf = MLPClassifier(solver='lbfgs', alpha=1e-5,
                     hidden_layer_sizes=(50, 1), random_state=1)
clf.fit(X, y)


y_pred_ANN =clf.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_ANN = confusion_matrix(y_test, y_pred_ANN)

######### AUC ##############
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_ANN , pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_ANN = metrics.auc(fpr, tpr)

######### AP ##############
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_ANN ))   
average_precision_score_ANN = average_precision_score(y_test, y_pred_ANN )

############# Bagged Decision Trees for regression #########
import pandas
from sklearn import model_selection
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
#url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
#names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
#dataframe = pandas.read_csv(url, names=names)
#array = dataframe.values
#X = array[:,0:8]
#Y = array[:,8]
seed = 7
kfold = model_selection.KFold(n_splits=10, random_state=seed)
cart = DecisionTreeClassifier()
num_trees = 100
model_Bagging = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)
model_Bagging.fit(X_train, y_train)

results = model_selection.cross_val_score(model_Bagging, X, y, cv=kfold)
print(results.mean())

y_pred_Bagged = model_Bagging.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_Bagged = confusion_matrix(y_test, y_pred_ANN)

######### AUC ##############
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_Bagged , pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_Bagged = metrics.auc(fpr, tpr)

######### AP ##############
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_Bagged ))   
average_precision_score_Bagged = average_precision_score(y_test, y_pred_Bagged )

############# Extra Trees regression ########
import pandas
from sklearn import model_selection
from sklearn.ensemble import ExtraTreesClassifier
seed = 3
num_trees = 100
max_features = 3
kfold = model_selection.KFold(n_splits=10, random_state=seed)
model_Extra_Trees = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)
model_Extra_Trees.fit(X_train, y_train)


results = model_selection.cross_val_score(model_Extra_Trees, X, y, cv=kfold)
print(results.mean())

y_pred_Extra = model_Extra_Trees.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_Extra = confusion_matrix(y_test, y_pred_ANN)

######### AUC ##############
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_Extra , pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_Extra = metrics.auc(fpr, tpr)

######### AP ##############
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_Extra ))   
average_precision_score_Extra = average_precision_score(y_test, y_pred_Extra )

# AdaBoost regression ################################
from sklearn import model_selection
from sklearn.ensemble import AdaBoostClassifier

seed = 6
num_trees = 100
kfold = model_selection.KFold(n_splits=10, random_state=seed)
model_AdaBoost = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)
model_AdaBoost.fit(X_train, y_train)


results = model_selection.cross_val_score(model_AdaBoost, X, y, cv=kfold)
print(results.mean())

y_pred_Adaboost = model_AdaBoost.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_Adaboost = confusion_matrix(y_test, y_pred_Adaboost)

######### AUC ##############
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_Adaboost , pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_Adaboost = metrics.auc(fpr, tpr)

######### AP ##############
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_Adaboost ))   
average_precision_score_Adaboost = average_precision_score(y_test, y_pred_Adaboost )

######## Stochastic Gradient Boosting Classification ####
from sklearn import model_selection
from sklearn.ensemble import GradientBoostingClassifier

seed = 6
num_trees = 100
kfold = model_selection.KFold(n_splits=10, random_state=seed)
model_GradientBoostingClassifier = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)
model_GradientBoostingClassifier.fit(X_train, y_train)


#results = model_selection.cross_val_score(GradientBoostingRegressor, X, y, cv=kfold)
#print(results.mean())

y_pred_SCB = model_GradientBoostingClassifier.predict(X_test)


# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm_SGB = confusion_matrix(y_test, y_pred_SCB)


######### AUC ##############
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_SCB , pos_label=1)
print ("AUC_logistic = ",metrics.auc(fpr, tpr))
AUC_SGB = metrics.auc(fpr, tpr)

######### AP ##############
from sklearn.metrics import average_precision_score
print ("average_precision_score = ",average_precision_score(y_test, y_pred_SCB ))   
average_precision_score_SGB = average_precision_score(y_test, y_pred_SCB )


### Export to excel ###################################
##########################################################

df1 = pd.DataFrame([
        [AUC_logistic,average_precision_score_Logistic ],
        [AUC_KNN,average_precision_score_KNN ],
        [AUC_SVM,average_precision_score_SVM  ],            
        [AUC_naive,average_precision_score_naive   ],            
        [AUC_DT ,average_precision_score_DT   ],            
        [AUC_RF ,average_precision_score_RF ],            
        [AUC_XGB ,average_precision_score_XGB ],            
        [AUC_ANN ,average_precision_score_ANN  ],            
        [AUC_Bagged ,average_precision_score_Bagged  ],            
        [AUC_Extra ,average_precision_score_Extra  ],            
        [AUC_Adaboost ,average_precision_score_Adaboost  ],            
        [AUC_SGB ,average_precision_score_SGB  ],            

                                            ],
                    index=[
                        'Logistic',
                        'KNN',
                        'SVM',
                        'Naive Bayes',
                        'DT',
                        'RF',
                        'XGB',
                        'ANN',
                        'Bagging',
                        'Extra Trees',
                        'AdaBoost',
                        'SGB'
                           ],
                            
                   columns=['AUC', 'precision_score'])

df1.to_excel("output.xlsx")  # doctest: +SKIP









### Receiver Operating Characteristic Curves Demystified (in Python) ###################################
##########################################################


import numpy as np
import matplotlib.pyplot as plt
def pdf(x, std, mean):
    const = 1.0 / np.sqrt(2*np.pi*(std**2))
    pdf_normal_dist = const*np.exp(-((x-mean)**2)/(2.0*(std**2)))
    return pdf_normal_dist
x = np.linspace(0, 1, num=100)
good_pdf = pdf(x,0.1,0.4)
bad_pdf = pdf(x,0.1,0.6)

def plot_pdf(good_pdf, bad_pdf, ax):
    ax.fill(x, good_pdf, "g", alpha=0.5)
    ax.fill(x, bad_pdf,"r", alpha=0.5)
    ax.set_xlim([0,1])
    ax.set_ylim([0,5])
    ax.set_title("Probability Distribution", fontsize=14)
    ax.set_ylabel('Counts', fontsize=12)
    ax.set_xlabel('P(X="bad")', fontsize=12)
    ax.legend(["good","bad"])
    
fig, ax = plt.subplots(1,1, figsize=(10,5))
plot_pdf(good_pdf, bad_pdf, ax)

def plot_roc(good_pdf, bad_pdf, ax):
    #Total
    total_bad = np.sum(bad_pdf)
    total_good = np.sum(good_pdf)
    #Cumulative sum
    cum_TP = 0
    cum_FP = 0
    #TPR and FPR list initialization
    TPR_list=[]
    FPR_list=[]
    #Iteratre through all values of x
    for i in range(len(x)):
        #We are only interested in non-zero values of bad
        if bad_pdf[i]>0:
            cum_TP+=bad_pdf[len(x)-1-i]
            cum_FP+=good_pdf[len(x)-1-i]
        FPR=cum_FP/total_good
        TPR=cum_TP/total_bad
        TPR_list.append(TPR)
        FPR_list.append(FPR)
    #Calculating AUC, taking the 100 timesteps into account
    auc=np.sum(TPR_list)/100
    #Plotting final ROC curve
    ax.plot(FPR_list, TPR_list)
    ax.plot(x,x, "--")
    ax.set_xlim([0,1])
    ax.set_ylim([0,1])
    ax.set_title("ROC Curve", fontsize=14)
    ax.set_ylabel('TPR', fontsize=12)
    ax.set_xlabel('FPR', fontsize=12)
    ax.grid()
    ax.legend(["AUC=%.3f"%auc])
    
fig, ax = plt.subplots(1,1, figsize=(10,5))
plot_roc(good_pdf, bad_pdf, ax)

fig, ax = plt.subplots(1,2, figsize=(10,5))
plot_pdf(good_pdf, bad_pdf, ax[0])
plot_roc(good_pdf, bad_pdf, ax[1])
plt.tight_layout()

x = np.linspace(0, 1, num=100)
fig, ax = plt.subplots(3,2, figsize=(10,12))
means_tuples = [(0.5,0.5),(0.4,0.6),(0.3,0.7)]
i=0
for good_mean, bad_mean in means_tuples:
    good_pdf = pdf(x, 0.1, good_mean)
    bad_pdf  = pdf(x, 0.1, bad_mean)
    plot_pdf(good_pdf, bad_pdf, ax[i,0])
    plot_roc(good_pdf, bad_pdf, ax[i,1])
    i+=1
plt.tight_layout()

############## ROC Comparsion chart ################

from sklearn.datasets import load_breast_cancer
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.model_selection import train_test_split

from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
import matplotlib
import matplotlib.pyplot as plt

plt.rcParams["font.family"] = "Times New Roman"


def roc_curve_and_score(y_test, pred_proba):
    fpr, tpr, _ = roc_curve(y_test.ravel(), pred_proba.ravel())
    roc_auc = roc_auc_score(y_test.ravel(), pred_proba.ravel())
    return fpr, tpr, roc_auc


plt.figure(figsize=(8, 6))
matplotlib.rcParams.update({'font.size': 14})
plt.grid()

fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_Logistic)
plt.plot(fpr, tpr, color='darkorange', lw=2,
         label='logistic ROC AUC={0:.3f}'.format(roc_auc))

fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_KNN)
plt.plot(fpr, tpr, color='green', lw=2,
         label='KNN ROC AUC={0:.3f}'.format(roc_auc))

fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_SVC)
plt.plot(fpr, tpr, color='crimson', lw=2,
         label='SVM ROC AUC={0:.3f}'.format(roc_auc))




fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_naive)
plt.plot(fpr, tpr, color='blue', lw=2,
         label='NBs ROC AUC={0:.3f}'.format(roc_auc))

fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_DT)
plt.plot(fpr, tpr, color='red', lw=2,
         label='DT ROC AUC={0:.3f}'.format(roc_auc))

fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_RF)
plt.plot(fpr, tpr, color='cyan', lw=2,
         label='RFs ROC AUC={0:.3f}'.format(roc_auc))

fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_XGB)
plt.plot(fpr, tpr, color='magenta', lw=2,
         label='XGBoost ROC AUC={0:.3f}'.format(roc_auc))

fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_ANN)
plt.plot(fpr, tpr, color='yellow', lw=2,
         label='ANNs ROC AUC={0:.3f}'.format(roc_auc))

fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_Bagged)
plt.plot(fpr, tpr, color='black', lw=2,
         label='Bagged ROC AUC={0:.3f}'.format(roc_auc))

fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_Extra)
plt.plot(fpr, tpr, color='brown', lw=2,
         label='Extra ROC AUC={0:.3f}'.format(roc_auc))

fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_Adaboost)
plt.plot(fpr, tpr, color='coral', lw=2,
         label='Adaboost ROC AUC={0:.3f}'.format(roc_auc))

fpr, tpr, roc_auc = roc_curve_and_score(y_test, y_pred_SCB)
plt.plot(fpr, tpr, color='darkgreen', lw=2,
         label='SGD ROC AUC={0:.3f}'.format(roc_auc))


plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')
plt.legend(loc="lower right")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('1 - Specificity')
plt.ylabel('Sensitivity')
plt.show()

